{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.6 64-bit ('base': conda)",
      "language": "python",
      "name": "python_defaultSpec_1598207596120"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "colab": {
      "name": "2. model_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "o1aJbVYBWSh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.misc import electrocardiogram\n",
        "from scipy import signal\n",
        "import scipy.integrate as integrate\n",
        "import scipy.fftpack as ff\n",
        "#!/usr/bin/env python\n",
        "\n",
        "import numpy as np, os, sys, joblib\n",
        "from scipy.io import loadmat\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from numpy import genfromtxt\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n",
        "from keras.optimizers import Adam\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Using TensorFlow backend.\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cBqh8xeWSh8",
        "colab_type": "text"
      },
      "source": [
        "# 1. Signal lecture \n",
        "#### Please note: \n",
        "For easier data analysis and features visualization, please use pandas (since its easier to use). But for the final signal (the one we need to integration), please use numpy format (convert to numpy using \"signal.values\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOgED0yLWSh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = f'features.csv'\n",
        "labels = f'labels.csv'\n",
        "testing = f'testing.csv'\n",
        "testing = genfromtxt(testing, delimiter=',')\n",
        "features = genfromtxt(features, delimiter=',')\n",
        "labels = genfromtxt(labels, delimiter=',')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIpbssJ6WSiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize data\n",
        "testing = tf.keras.utils.normalize(testing)\n",
        "features = tf.keras.utils.normalize(features)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "joCy766RWSiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b08528f8-8914-43bc-ccf7-28bc1faf3d25"
      },
      "source": [
        "print(features.dtype)\n",
        "print(testing.dtype)\n",
        "print(labels.dtype)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "float64\nfloat64\nfloat64\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "nVbNkigxWSiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "80cf768f-9c65-4d79-c696-d2c032b7935b"
      },
      "source": [
        "## Inside the run_12ECG_code we must consider the following structure (1,14)\n",
        "testing_reshape = testing.reshape(1, -1)\n",
        "imputer=SimpleImputer().fit(testing_reshape)\n",
        "testing_reshape = imputer.transform(testing_reshape)\n",
        "print(testing_reshape.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1, 14)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "D7yhR6u8WSif",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b85fbdb9-116f-481f-e822-b5f8b7f82c60"
      },
      "source": [
        "# Training set bust consider the next structure\n",
        "print(features.shape, labels.shape)\n",
        "4812*14"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(4813, 14) (4813, 9)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "67368"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "nrw7nEMkWSin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "536def75-fdac-4716-c424-ee026069bda8"
      },
      "source": [
        "# Since labels are organized in hot-encoding format and we need the index Number, define decode:\n",
        "def decode(datum):\n",
        "    return np.argmax(datum)labels\n",
        "label_final = []\n",
        "    \n",
        "# Extract hot-encode format to normal format\n",
        "for i in range(labels.shape[0]):\n",
        "    label = labels[i]\n",
        "    decoded_labels = decode(label)\n",
        "    label_final.append(decoded_labels)\n",
        "# Convert list to np array\n",
        "label_final = np.array(label_final)\n",
        "label_final = np.uint8(label_final)\n",
        "print(label_final.dtype)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "uint8\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIWK_YAUWSir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ee9de424-2ccc-4957-856c-fe5bf58373df"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(4813, 14)"
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iDRRUMXWSiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "b6ab67d8-5a31-47a8-cc69-0b473e6f16ac",
        "tags": []
      },
      "source": [
        "model_0 = Sequential()\n",
        "model_0.add(Dense(12, input_dim = 14, activation=\"softmax\"))\n",
        "model_0.add(Dense(128, activation = 'softmax'))\n",
        "model_0.add(Dense(9, activation = 'softmax'))\n",
        "# Compile the model\n",
        "model_0.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model_0.fit(features,labels, epochs=15, batch_size=10,  verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/15\n - 1s - loss: 2.2505 - accuracy: 0.2217\nEpoch 2/15\n - 1s - loss: 2.1796 - accuracy: 0.2256\nEpoch 3/15\n - 1s - loss: 2.1687 - accuracy: 0.2256\nEpoch 4/15\n - 1s - loss: 2.1669 - accuracy: 0.2256\nEpoch 5/15\n - 1s - loss: 2.1668 - accuracy: 0.2256\nEpoch 6/15\n - 1s - loss: 2.1668 - accuracy: 0.2256\nEpoch 7/15\n - 1s - loss: 2.1667 - accuracy: 0.2256\nEpoch 8/15\n - 1s - loss: 2.1670 - accuracy: 0.2256\nEpoch 9/15\n - 1s - loss: 2.1669 - accuracy: 0.2256\nEpoch 10/15\n - 1s - loss: 2.1671 - accuracy: 0.2256\nEpoch 11/15\n - 1s - loss: 2.1668 - accuracy: 0.2256\nEpoch 12/15\n - 1s - loss: 2.1671 - accuracy: 0.2256\nEpoch 13/15\n - 1s - loss: 2.1670 - accuracy: 0.2256\nEpoch 14/15\n - 1s - loss: 2.1669 - accuracy: 0.2256\nEpoch 15/15\n - 1s - loss: 2.1670 - accuracy: 0.2256\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.callbacks.History at 0x7fa5b42d2a90>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWtLXlrtWSi2",
        "colab_type": "text"
      },
      "source": [
        "#### Model 1 : branch NN_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_H6_MeU1WSi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "d80d7e24-d383-4215-943a-5a23fd376e93"
      },
      "source": [
        "print(\"training model NN_1\")\n",
        "############# MODEL 1 - NN ######################\n",
        "model_1 = tf.keras.models.Sequential()\n",
        "model_1.add(tf.keras.layers.Flatten())\n",
        "# use 128 neurons & use relu act func\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "\n",
        "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
        "# the final output layer must be Dense and must fit # classifications and must use probability distribution instead of an activation function\n",
        "model_1.add(tf.keras.layers.Dense(9, activation = tf.nn.softmax))\n",
        "    \n",
        "# Compile \n",
        "model_1.compile(\n",
        "optimizer= 'adam' ,# NN intends to minimize losss, not maximize accuracy\n",
        "loss = 'sparse_categorical_crossentropy',\n",
        "metrics = ['accuracy']\n",
        ")\n",
        "# Fit the model appropiatelly\n",
        "model_1.fit(features, label_final, epochs=10)\n",
        "val_loss, val_acc = model_1.evaluate(features, label_final)\n",
        "print(\"The model is trained\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "training model NN_1\nTrain on 4813 samples\nEpoch 1/10\n4813/4813 [==============================] - 1s 262us/sample - loss: 2.0668 - accuracy: 0.2171\nEpoch 2/10\n4813/4813 [==============================] - 0s 101us/sample - loss: 2.0568 - accuracy: 0.2256\nEpoch 3/10\n4813/4813 [==============================] - 0s 104us/sample - loss: 2.0547 - accuracy: 0.2256\nEpoch 4/10\n4813/4813 [==============================] - 0s 98us/sample - loss: 2.0526 - accuracy: 0.2180\nEpoch 5/10\n4813/4813 [==============================] - 1s 108us/sample - loss: 2.0529 - accuracy: 0.2256\nEpoch 6/10\n4813/4813 [==============================] - 0s 101us/sample - loss: 2.0513 - accuracy: 0.2256\nEpoch 7/10\n4813/4813 [==============================] - 1s 129us/sample - loss: 2.0535 - accuracy: 0.2256\nEpoch 8/10\n4813/4813 [==============================] - 1s 158us/sample - loss: 2.0520 - accuracy: 0.2256\nEpoch 9/10\n4813/4813 [==============================] - 1s 165us/sample - loss: 2.0516 - accuracy: 0.2256\nEpoch 10/10\n4813/4813 [==============================] - 1s 164us/sample - loss: 2.0522 - accuracy: 0.2256\n4813/4813 [==============================] - 0s 97us/sample - loss: 2.0490 - accuracy: 0.2256\nThe model is trained\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_bUuekRPWSi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "5f1a0a42-4170-4156-8f00-5ad9b1c77e83"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  1920      \n_________________________________________________________________\ndense_1 (Dense)              multiple                  16512     \n_________________________________________________________________\ndense_2 (Dense)              multiple                  16512     \n_________________________________________________________________\ndense_3 (Dense)              multiple                  16512     \n_________________________________________________________________\ndense_4 (Dense)              multiple                  16512     \n_________________________________________________________________\ndense_5 (Dense)              multiple                  16512     \n_________________________________________________________________\ndense_6 (Dense)              multiple                  1161      \n=================================================================\nTotal params: 85,641\nTrainable params: 85,641\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "phoAjijpWSjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "052bacb9-9fcf-4bf7-e3e9-5a42f0beff8e"
      },
      "source": [
        "# Save model.\n",
        "model_1.save(\"NN_1.model\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:From /home/sebasmos/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: NN_1.model/assets\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "oZZviJW8WSjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "2d5b92da-42db-4869-fb1d-fe8053debc5f"
      },
      "source": [
        "print(features.shape, label_final.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(4813, 14) (4813,)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO6zd8kGWSjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6699d0c7-d134-4e38-d9f6-bf20a157b9b8"
      },
      "source": [
        "nn_model = tf.keras.models.load_model('NN_1.model/')\n",
        "nn_model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.saving.saved_model.load.Sequential at 0x7fa5b42c0a50>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eegAbIA9WSjU",
        "colab_type": "text"
      },
      "source": [
        "### current label & score\n",
        "1. From the baseline code we had that the original model saved three things:`model`, `imputer`, `classes` on a file called `finalized_model.sav` from the joblib library. \n",
        "2. The Imputer used in the training code might be affecting the testing set. Imputer replaces np.nan values inside the features and it is saved only once for the entire traininset, therefore it must be saved to be re used in the driver.py code\n",
        "3. `current_label`: is originally extracted using:\n",
        "\n",
        " `current_label = model.predict(feats_reshape)[0]`:  Array of float64 (9,) # array([0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
        " \n",
        " `current_label=current_label.astype(int)`:  Array of int32 (9,) # array([0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
        "\n",
        " `current_score = model.predict_proba(feats_reshape)`: List of 9 which is converted to np.array # array([0.04, 0.74, 0.02, 0.04, 0.09, 0.02, 0.  , 0.03, 0.72])\n",
        "\n",
        " `classes`: This function is stored as well and contains the classes tags:  \n",
        " \n",
        " classes = ['164884008', '164889003', '164909002', '164931005', '270492004', '284470004', '426783006', '429622005', '59118001']\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "iGbu-X11WSjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5b6c4632-e87f-4e0c-e56d-1355e72d8951"
      },
      "source": [
        "# adding [0] for extracting the values from the array\n",
        "current_label = nn_model.predict([testing_reshape])[0]\n",
        "current_label = current_label.astype(int)\n",
        "current_label"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmIeKRKXWSja",
        "colab_type": "text"
      },
      "source": [
        "Evidently this will be zero all the time unless prediction is really high. Therefore we can use argmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "yucMgWOoWSjb",
        "outputId": "ed4aa5a2-345f-4137-934c-b0f5377ccc8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.09789988, 0.17403406, 0.02624198, 0.0338447 , 0.10129697,\n       0.08337908, 0.13300598, 0.12525333, 0.22504395], dtype=float32)"
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "current_label = nn_model.predict(testing_reshape)[0]\n",
        "current_label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "y4gyETsvWSje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "14b7b06d-cecf-4ff0-cb4a-16498c2d0b8f"
      },
      "source": [
        "# Using the baseline probaility we obtain:\n",
        "current_score = nn_model.predict_proba(testing_reshape)\n",
        "current_score"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.09789988, 0.17403406, 0.02624198, 0.0338447 , 0.10129697,\n        0.08337908, 0.13300598, 0.12525333, 0.22504395]], dtype=float32)"
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mMMICSUWSjl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1a6f9b44-cbaf-40ab-ae25-5c1e58725997"
      },
      "source": [
        "# Suppose softmax model \n",
        "probability_model = tf.keras.Sequential([nn_model,tf.keras.layers.Softmax()])  \n",
        "current_score = nn_model.predict(testing_reshape)\n",
        "current_score"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0.09789988, 0.17403406, 0.02624198, 0.0338447 , 0.10129697,\n        0.08337908, 0.13300598, 0.12525333, 0.22504395]], dtype=float32)"
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuQttKlhWSjo",
        "colab_type": "text"
      },
      "source": [
        "From this results we can infer that nn_model.predict is equivalent to probability_model from Softmax performace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD24N5lLWSjo",
        "colab_type": "text"
      },
      "source": [
        "Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "tvw28GC2WSjp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "1ae86050-6565-4cc3-8ef8-cebd1fc8561d"
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "prediction = nn_model.predict([testing_reshape])[0]\n",
        "print(prediction)\n",
        "prediction = np.argmax(prediction)\n",
        "encoded = to_categorical(prediction)\n",
        "current_label = encoded.astype(int)\n",
        "print(current_label)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[0.09789988 0.17403406 0.02624198 0.0338447  0.10129697 0.08337908\n 0.13300598 0.12525333 0.22504395]\n[0 0 0 0 0 0 0 0 1]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtI6sp0RWSjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = [0.9403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199, 0.08466987, 0.1342014,  0.11385558, 0.9403204]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQqGHlisWSjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6fd4a868-9b14-4cd3-8533-94fcd3213076"
      },
      "source": [
        "test = np.array(test)\n",
        "test"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.9403204 , 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n       0.08466987, 0.1342014 , 0.11385558, 0.9403204 ])"
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDvXcwkwWSj5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e8d6464f-f70c-4e5c-df80-71c2b7e47071"
      },
      "source": [
        "current_label = test.astype(int)\n",
        "current_label"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HHtzkGbWSj8",
        "colab_type": "text"
      },
      "source": [
        "#### Model 2: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "mWqS0Ed3WSj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8dc3edd0-106f-4d14-9f8c-a70afbaf3ac1"
      },
      "source": [
        "sequence_size = features.shape[1]\n",
        "n_features=1\n",
        "print(features.shape, label_final.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(4813, 14) (4813, 1)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "YhSgP3MIWSkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "f4ed2f19-6230-4653-bfde-e7ffa37285f7"
      },
      "source": [
        "cnn_model = Sequential([\n",
        "Conv1D(\n",
        "    filters=1,\n",
        "    kernel_size=4,\n",
        "    strides=1,\n",
        "    input_shape=(14, 1),\n",
        "    padding=\"same\",\n",
        "    activation=\"relu\"\n",
        "),\n",
        "Flatten(),\n",
        "Dropout(0.5),\n",
        "Dense(\n",
        "    9,\n",
        "    activation=\"sigmoid\",\n",
        "    name=\"output\",\n",
        ")\n",
        "])\n",
        "optimizer = Adam(lr=0.001)\n",
        "# Compiling the model\n",
        "cnn_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "cnn_model.summary()\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_2 (Conv1D)            (None, 14, 1)             5         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 14)                0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 14)                0         \n_________________________________________________________________\noutput (Dense)               (None, 9)                 135       \n=================================================================\nTotal params: 140\nTrainable params: 140\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_BKv1Xd8WSkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0694f6f0-26e0-47ef-f990-3ea546869d87"
      },
      "source": [
        "feat_cnn = np.expand_dims(features, axis=2) \n",
        "label_cnn = label_final.reshape(-1,1)\n",
        "print(\"features shape: \", feat_cnn.shape)\n",
        "print(\"label features: \", label_cnn.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "features shape:  (4813, 14, 1)\nlabel features:  (4813, 1)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZZBHAJFWSkL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5d678db4-78aa-43f8-8880-9ad7c476826c"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(4813, 9)"
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "YPsXWVNMWSkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "cc14f6ad-ba06-4848-e106-446cf387207c"
      },
      "source": [
        "cnn_model.fit(feat_cnn, labels,  epochs=15, batch_size=10,  verbose=2)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/15\n - 1s - loss: 0.3467 - accuracy: 0.8816\nEpoch 2/15\n - 1s - loss: 0.3458 - accuracy: 0.8816\nEpoch 3/15\n - 1s - loss: 0.3456 - accuracy: 0.8816\nEpoch 4/15\n - 1s - loss: 0.3456 - accuracy: 0.8816\nEpoch 5/15\n - 1s - loss: 0.3452 - accuracy: 0.8816\nEpoch 6/15\n - 1s - loss: 0.3453 - accuracy: 0.8816\nEpoch 7/15\n - 1s - loss: 0.3446 - accuracy: 0.8816\nEpoch 8/15\n - 1s - loss: 0.3446 - accuracy: 0.8816\nEpoch 9/15\n - 1s - loss: 0.3445 - accuracy: 0.8816\nEpoch 10/15\n - 1s - loss: 0.3438 - accuracy: 0.8816\nEpoch 11/15\n - 1s - loss: 0.3436 - accuracy: 0.8816\nEpoch 12/15\n - 1s - loss: 0.3441 - accuracy: 0.8816\nEpoch 13/15\n - 1s - loss: 0.3436 - accuracy: 0.8816\nEpoch 14/15\n - 1s - loss: 0.3434 - accuracy: 0.8816\nEpoch 15/15\n - 1s - loss: 0.3431 - accuracy: 0.8816\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.callbacks.History at 0x7fa53c2d2110>"
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing_reshape_cnn = np.expand_dims(testing_reshape, axis=2) \n",
        "testing_reshape_cnn.shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tjohu4VWSkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feat_final and labels:  acc_88.16\n",
        "prediction_cnn = cnn_model.predict([testing_reshape_cnn])[0]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error when checking input: expected conv1d_2_input to have 3 dimensions, but got array with shape (1, 14)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e5c32866f5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# feat_final and labels:  acc_88.16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtesting_reshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_2_input to have 3 dimensions, but got array with shape (1, 14)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}