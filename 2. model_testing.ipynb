{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import electrocardiogram\n",
    "from scipy import signal\n",
    "import scipy.integrate as integrate\n",
    "import scipy.fftpack as ff\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np, os, sys, joblib\n",
    "from scipy.io import loadmat\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from get_12ECG_features import get_12ECG_features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Signal lecture \n",
    "#### Please note: \n",
    "For easier data analysis and features visualization, please use pandas (since its easier to use). But for the final signal (the one we need to integration), please use numpy format (convert to numpy using \"signal.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = f'features.csv'\n",
    "labels = f'labels.csv'\n",
    "testing = f'testing.csv'\n",
    "testing = genfromtxt(testing, delimiter=',')\n",
    "features = genfromtxt(features, delimiter=',')\n",
    "labels = genfromtxt(labels, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "testing = tf.keras.utils.normalize(testing)\n",
    "features = tf.keras.utils.normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "float64\nfloat64\nfloat64\n"
    }
   ],
   "source": [
    "print(features.dtype)\n",
    "print(testing.dtype)\n",
    "print(label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 14)\n"
    }
   ],
   "source": [
    "## Inside the run_12ECG_code we must consider the following structure (1,14)\n",
    "testing_reshape = testing.reshape(1, -1)\n",
    "imputer=SimpleImputer().fit(testing_reshape)\n",
    "testing_reshape = imputer.transform(testing_reshape)\n",
    "print(testing_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813, 9)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67368"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Training set bust consider the next structure\n",
    "print(features.shape, labels.shape)\n",
    "4812*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "uint8\n"
    }
   ],
   "source": [
    "# Since labels are organized in hot-encoding format and we need the index Number, define decode:\n",
    "def decode(datum):\n",
    "    return np.argmax(datum)\n",
    "label_final = []\n",
    "    \n",
    "# Extract hot-encode format to normal format\n",
    "for i in range(labels.shape[0]):\n",
    "    label = labels[i]\n",
    "    decoded_labels = decode(label)\n",
    "    label_final.append(decoded_labels)\n",
    "# Convert list to np array\n",
    "label_final = np.array(label_final)\n",
    "label_final = np.uint8(label_final)\n",
    "print(label_final.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 : branch NN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training model NN_1\nEpoch 1/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0685 - accuracy: 0.2182\nEpoch 2/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0555 - accuracy: 0.2256\nEpoch 3/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0532 - accuracy: 0.2256\nEpoch 4/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0553 - accuracy: 0.2256\nEpoch 5/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0544 - accuracy: 0.2256\nEpoch 6/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0522 - accuracy: 0.2256\nEpoch 7/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0533 - accuracy: 0.2256\nEpoch 8/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0524 - accuracy: 0.2256\nEpoch 9/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0518 - accuracy: 0.2256\nEpoch 10/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0522 - accuracy: 0.2256\n151/151 [==============================] - 0s 739us/step - loss: 2.0509 - accuracy: 0.2256\nThe model is trained\n"
    }
   ],
   "source": [
    "print(\"training model NN_1\")\n",
    "############# MODEL 1 - NN ######################\n",
    "model_1 = tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.layers.Flatten())\n",
    "# use 128 neurons & use relu act func\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "# the final output layer must be Dense and must fit # classifications and must use probability distribution instead of an activation function\n",
    "model_1.add(tf.keras.layers.Dense(9, activation = tf.nn.softmax))\n",
    "    \n",
    "# Compile \n",
    "model_1.compile(\n",
    "optimizer= 'adam' ,# NN intends to minimize losss, not maximize accuracy\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics = ['accuracy']\n",
    ")\n",
    "# Fit the model appropiatelly\n",
    "model_1.fit(features, label_final, epochs=10)\n",
    "val_loss, val_acc = model_1.evaluate(features, label_final)\n",
    "print(\"The model is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_1 (Flatten)          (None, 14)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 128)               1920      \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_9 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_10 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_11 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_12 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_13 (Dense)             (None, 9)                 1161      \n=================================================================\nTotal params: 85,641\nTrainable params: 85,641\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: NN_1.model\\assets\n"
    }
   ],
   "source": [
    "# Save model.\n",
    "model_1.save(\"NN_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813,)\n"
    }
   ],
   "source": [
    "print(features.shape, label_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.engine.sequential.Sequential at 0x26a8dbf0708>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nn_model = tf.keras.models.load_model('NN_1.model/')\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### current label & score\n",
    "From the baseline code we had that the original model saved three things:`model`, `imputer`, `classes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.09403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n       0.08466987, 0.1342014 , 0.11385558, 0.25327644], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "predictions = nn_model.predict([testing_reshape])[0]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda91809b139dd24b97ab06595f752137a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}