{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import electrocardiogram\n",
    "from scipy import signal\n",
    "import scipy.integrate as integrate\n",
    "import scipy.fftpack as ff\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np, os, sys, joblib\n",
    "from scipy.io import loadmat\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from get_12ECG_features import get_12ECG_features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Signal lecture \n",
    "#### Please note: \n",
    "For easier data analysis and features visualization, please use pandas (since its easier to use). But for the final signal (the one we need to integration), please use numpy format (convert to numpy using \"signal.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = f'features.csv'\n",
    "labels = f'labels.csv'\n",
    "testing = f'testing.csv'\n",
    "testing = genfromtxt(testing, delimiter=',')\n",
    "features = genfromtxt(features, delimiter=',')\n",
    "labels = genfromtxt(labels, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "testing = tf.keras.utils.normalize(testing)\n",
    "features = tf.keras.utils.normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "float64\nfloat64\nfloat64\n"
    }
   ],
   "source": [
    "print(features.dtype)\n",
    "print(testing.dtype)\n",
    "print(label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 14)\n"
    }
   ],
   "source": [
    "## Inside the run_12ECG_code we must consider the following structure (1,14)\n",
    "testing_reshape = testing.reshape(1, -1)\n",
    "imputer=SimpleImputer().fit(testing_reshape)\n",
    "testing_reshape = imputer.transform(testing_reshape)\n",
    "print(testing_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813, 9)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67368"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Training set bust consider the next structure\n",
    "print(features.shape, labels.shape)\n",
    "4812*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "uint8\n"
    }
   ],
   "source": [
    "# Since labels are organized in hot-encoding format and we need the index Number, define decode:\n",
    "def decode(datum):\n",
    "    return np.argmax(datum)\n",
    "label_final = []\n",
    "    \n",
    "# Extract hot-encode format to normal format\n",
    "for i in range(labels.shape[0]):\n",
    "    label = labels[i]\n",
    "    decoded_labels = decode(label)\n",
    "    label_final.append(decoded_labels)\n",
    "# Convert list to np array\n",
    "label_final = np.array(label_final)\n",
    "label_final = np.uint8(label_final)\n",
    "print(label_final.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4813,)"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "label_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 : branch NN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training model NN_1\nEpoch 1/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0685 - accuracy: 0.2182\nEpoch 2/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0555 - accuracy: 0.2256\nEpoch 3/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0532 - accuracy: 0.2256\nEpoch 4/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0553 - accuracy: 0.2256\nEpoch 5/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0544 - accuracy: 0.2256\nEpoch 6/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0522 - accuracy: 0.2256\nEpoch 7/10\n151/151 [==============================] - 0s 2ms/step - loss: 2.0533 - accuracy: 0.2256\nEpoch 8/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0524 - accuracy: 0.2256\nEpoch 9/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0518 - accuracy: 0.2256\nEpoch 10/10\n151/151 [==============================] - 0s 1ms/step - loss: 2.0522 - accuracy: 0.2256\n151/151 [==============================] - 0s 739us/step - loss: 2.0509 - accuracy: 0.2256\nThe model is trained\n"
    }
   ],
   "source": [
    "print(\"training model NN_1\")\n",
    "############# MODEL 1 - NN ######################\n",
    "model_1 = tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.layers.Flatten())\n",
    "# use 128 neurons & use relu act func\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "# the final output layer must be Dense and must fit # classifications and must use probability distribution instead of an activation function\n",
    "model_1.add(tf.keras.layers.Dense(9, activation = tf.nn.softmax))\n",
    "    \n",
    "# Compile \n",
    "model_1.compile(\n",
    "optimizer= 'adam' ,# NN intends to minimize losss, not maximize accuracy\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics = ['accuracy']\n",
    ")\n",
    "# Fit the model appropiatelly\n",
    "model_1.fit(features, label_final, epochs=10)\n",
    "val_loss, val_acc = model_1.evaluate(features, label_final)\n",
    "print(\"The model is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_1 (Flatten)          (None, 14)                0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 128)               1920      \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_9 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_10 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_11 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_12 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_13 (Dense)             (None, 9)                 1161      \n=================================================================\nTotal params: 85,641\nTrainable params: 85,641\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: NN_1.model\\assets\n"
    }
   ],
   "source": [
    "# Save model.\n",
    "model_1.save(\"NN_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813,)\n"
    }
   ],
   "source": [
    "print(features.shape, label_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.engine.sequential.Sequential at 0x26a8dbf0708>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nn_model = tf.keras.models.load_model('NN_1.model/')\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### current label & score\n",
    "1. From the baseline code we had that the original model saved three things:`model`, `imputer`, `classes` on a file called `finalized_model.sav` from the joblib library. \n",
    "2. The Imputer used in the training code might be affecting the testing set. Imputer replaces np.nan values inside the features and it is saved only once for the entire traininset, therefore it must be saved to be re used in the driver.py code\n",
    "3. `current_label`: is originally extracted using:\n",
    "\n",
    " `current_label = model.predict(feats_reshape)[0]`:  Array of float64 (9,) # array([0., 1., 0., 0., 0., 0., 0., 0., 1.])\n",
    " \n",
    " `current_label=current_label.astype(int)`:  Array of int32 (9,) # array([0, 1, 0, 0, 0, 0, 0, 0, 1])\n",
    "\n",
    " `current_score = model.predict_proba(feats_reshape)`: List of 9 which is converted to np.array # array([0.04, 0.74, 0.02, 0.04, 0.09, 0.02, 0.  , 0.03, 0.72])\n",
    "\n",
    " `classes`: This function is stored as well and contains the classes tags:  \n",
    " \n",
    " classes = ['164884008', '164889003', '164909002', '164931005', '270492004', '284470004', '426783006', '429622005', '59118001']\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# adding [0] for extracting the values from the array\n",
    "current_label = nn_model.predict([testing_reshape])[0]\n",
    "current_label = current_label.astype(int)\n",
    "current_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently this will be zero all the time unless prediction is really high. Therefore we can use argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.09403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n       0.08466987, 0.1342014 , 0.11385558, 0.25327644], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "current_label = nn_model.predict(testing_reshape)[0]\n",
    "current_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From <ipython-input-38-c0a5c3495531>:1: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\nInstructions for updating:\nPlease use `model.predict()` instead.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.09403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n        0.08466987, 0.1342014 , 0.11385558, 0.25327644]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Using the baseline probaility we obtain:\n",
    "current_score = nn_model.predict_proba(testing_reshape)\n",
    "current_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0.09403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n        0.08466987, 0.1342014 , 0.11385558, 0.25327644]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# Suppose softmax model \n",
    "probability_model = tf.keras.Sequential([nn_model,tf.keras.layers.Softmax()])  \n",
    "current_score = nn_model.predict(testing_reshape)\n",
    "current_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this results we can infer that nn_model.predict is equivalent to probability_model from Softmax performace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.09403204 0.16651522 0.02546168 0.03028586 0.09770199 0.08466987\n 0.1342014  0.11385558 0.25327644]\n[0 0 0 0 0 0 0 0 1]\n"
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "prediction = nn_model.predict([testing_reshape])[0]\n",
    "print(prediction)\n",
    "prediction = np.argmax(prediction)\n",
    "encoded = to_categorical(prediction)\n",
    "current_label = encoded.astype(int)\n",
    "print(current_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [0.9403204, 0.16651522, 0.02546168, 0.03028586, 0.09770199, 0.08466987, 0.1342014,  0.11385558, 0.9403204]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.9403204 , 0.16651522, 0.02546168, 0.03028586, 0.09770199,\n       0.08466987, 0.1342014 , 0.11385558, 0.9403204 ])"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "test = np.array(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "current_label = test.astype(int)\n",
    "current_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813,)\n"
    }
   ],
   "source": [
    "sequence_size = features.shape[1]\n",
    "n_features=1\n",
    "print(features.shape, label_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_7 (Conv1D)            (None, 14, 1)             5         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 14)                0         \n_________________________________________________________________\ndropout_7 (Dropout)          (None, 14)                0         \n_________________________________________________________________\noutput (Dense)               (None, 1)                 15        \n=================================================================\nTotal params: 20\nTrainable params: 20\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "cnn_model = Sequential([\n",
    "Conv1D(\n",
    "    filters=1,\n",
    "    kernel_size=4,\n",
    "    strides=1,\n",
    "    input_shape=(14, 1),\n",
    "    padding=\"same\",\n",
    "    activation=\"relu\"\n",
    "),\n",
    "Flatten(),\n",
    "Dropout(0.5),\n",
    "Dense(\n",
    "    1,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"output\",\n",
    ")\n",
    "])\n",
    "optimizer = Adam(lr=0.001)\n",
    "# Compiling the model\n",
    "cnn_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "features shape:  (4813, 14, 1)\nlabel features:  (4813, 1)\n"
    }
   ],
   "source": [
    "feat_final = np.expand_dims(features, axis=2) \n",
    "label_final = label_final.reshape(-1,1)\n",
    "print(\"features shape: \", feat_final.shape)\n",
    "print(\"label features: \", label_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(4813, 1)"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "label_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "`updates` argument is not supported during eager execution. You passed: [<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[0.]],\n\n       [[0.]],\n\n       [[0.]],\n\n       [[0.]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[0.]],\n\n       [[0.]],\n\n       [[0.]],\n\n       [[0.]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[-0.6989074 ]],\n\n       [[ 0.46536762]],\n\n       [[-0.36386883]],\n\n       [[ 0.20603174]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[ 0.4822145 ],\n       [-0.56496817],\n       [ 0.3284815 ],\n       [-0.59510446],\n       [ 0.5000313 ],\n       [-0.17926222],\n       [ 0.28428292],\n       [-0.25374556],\n       [ 0.24831945],\n       [-0.5202395 ],\n       [-0.54887146],\n       [-0.49732357],\n       [-0.3177168 ],\n       [ 0.39911968]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0>]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-0ffa658c6a05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_final\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[0mfit_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[0mfit_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetrics_updates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   3010\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[0;32m   3011\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3012\u001b[1;33m                                      **kwargs)\n\u001b[0m\u001b[0;32m   3013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   3931\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3932\u001b[0m       raise ValueError('`updates` argument is not supported during '\n\u001b[1;32m-> 3933\u001b[1;33m                        'eager execution. You passed: %s' % (updates,))\n\u001b[0m\u001b[0;32m   3934\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_utils\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `updates` argument is not supported during eager execution. You passed: [<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[0.]],\n\n       [[0.]],\n\n       [[0.]],\n\n       [[0.]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[0.]],\n\n       [[0.]],\n\n       [[0.]],\n\n       [[0.]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(4, 1, 1) dtype=float32, numpy=\narray([[[-0.6989074 ]],\n\n       [[ 0.46536762]],\n\n       [[-0.36386883]],\n\n       [[ 0.20603174]]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(14, 1) dtype=float32, numpy=\narray([[ 0.4822145 ],\n       [-0.56496817],\n       [ 0.3284815 ],\n       [-0.59510446],\n       [ 0.5000313 ],\n       [-0.17926222],\n       [ 0.28428292],\n       [-0.25374556],\n       [ 0.24831945],\n       [-0.5202395 ],\n       [-0.54887146],\n       [-0.49732357],\n       [-0.3177168 ],\n       [ 0.39911968]], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>, <tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0>, <tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.0>]"
     ]
    }
   ],
   "source": [
    "cnn_model.fit(feat_final, label_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda91809b139dd24b97ab06595f752137a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}