{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import electrocardiogram\n",
    "from scipy import signal\n",
    "import scipy.integrate as integrate\n",
    "import scipy.fftpack as ff\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np, os, sys, joblib\n",
    "from scipy.io import loadmat\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from get_12ECG_features import get_12ECG_features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, LSTM, Dense, Dropout, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Signal lecture - using A0001 sample\n",
    "#### Please note: \n",
    "For easier data analysis and features visualization, please use pandas (since its easier to use). But for the final signal (the one we need to integration), please use numpy format (convert to numpy using \"signal.values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = f'features.csv'\n",
    "labels = f'labels.csv'\n",
    "testing = f'testing.csv'\n",
    "testing = genfromtxt(testing, delimiter=',')\n",
    "features = genfromtxt(features, delimiter=',')\n",
    "labels = genfromtxt(labels, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = tf.keras.utils.normalize(testing)\n",
    "\n",
    "features = tf.keras.utils.normalize(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "float64\nfloat64\nfloat64\n"
    }
   ],
   "source": [
    "print(features.dtype)\n",
    "print(testing.dtype)\n",
    "print(label.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "min testing:  [ 8.18680069e-14  1.07721062e-15  1.35874940e-11  4.27676526e-08\n  1.38626234e-11  6.32003060e-08  7.47888383e-12  3.24457787e-08\n  5.31321232e-08  1.00000000e+00 -2.32469180e-16 -4.49220193e-16\n -1.20301183e-15 -1.88455344e-15] max testing:  [ 8.18680069e-14  1.07721062e-15  1.35874940e-11  4.27676526e-08\n  1.38626234e-11  6.32003060e-08  7.47888383e-12  3.24457787e-08\n  5.31321232e-08  1.00000000e+00 -2.32469180e-16 -4.49220193e-16\n -1.20301183e-15 -1.88455344e-15]\n"
    }
   ],
   "source": [
    "print(\"min testing: \", min(testing), \"max testing: \", max(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 14)\n"
    }
   ],
   "source": [
    "testing_reshape = testing.reshape(1, -1)\n",
    "imputer=SimpleImputer().fit(testing_reshape)\n",
    "testing_reshape = imputer.transform(testing_reshape)\n",
    "print(testing_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813, 9)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "67368"
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "print(features.shape, labels.shape)\n",
    "4812*14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(9)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training the model\nuint8\nEpoch 1/3\n151/151 [==============================] - 0s 1ms/step - loss: 2.0675 - accuracy: 0.2188\nEpoch 2/3\n151/151 [==============================] - 0s 2ms/step - loss: 2.0541 - accuracy: 0.2256\nEpoch 3/3\n151/151 [==============================] - 0s 2ms/step - loss: 2.0538 - accuracy: 0.2256\n151/151 [==============================] - 0s 1ms/step - loss: 2.0534 - accuracy: 0.2256\nThe model is trained\n"
    }
   ],
   "source": [
    "print(\"training the model\")\n",
    "############# MODEL 1 - NN ######################\n",
    "model_1 = tf.keras.models.Sequential()\n",
    "model_1.add(tf.keras.layers.Flatten())\n",
    "# use 128 neurons & use relu act func\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "\n",
    "model_1.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\n",
    "# the final output layer must be Dense and must fit # classifications and must use probability distribution instead of an activation function\n",
    "model_1.add(tf.keras.layers.Dense(9, activation = tf.nn.softmax))\n",
    "    \n",
    "# Compile \n",
    "model_1.compile(\n",
    "optimizer= 'adam' ,# NN intends to minimize losss, not maximize accuracy\n",
    "loss = 'sparse_categorical_crossentropy',\n",
    "metrics = ['accuracy']\n",
    ")\n",
    "label_final = []\n",
    "    \n",
    "# Extract hot-encode format to normal format\n",
    "for i in range(labels.shape[0]):\n",
    "    label = labels[i]\n",
    "    decoded_labels = decode(label)\n",
    "    label_final.append(decoded_labels)\n",
    "# Convert list to np array\n",
    "label_final = np.array(label_final)\n",
    "label_final = np.uint8(label_final)\n",
    "print(label_final.dtype)\n",
    "# Fit the model appropiatelly\n",
    "model_1.fit(features, label_final, epochs=10)\n",
    "val_loss, val_acc = model_1.evaluate(features, label_final)\n",
    "print(\"The model is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten_9 (Flatten)          (None, 14)                0         \n_________________________________________________________________\ndense_30 (Dense)             (None, 128)               1920      \n_________________________________________________________________\ndense_31 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_32 (Dense)             (None, 9)                 1161      \n=================================================================\nTotal params: 19,593\nTrainable params: 19,593\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: NN_1.model\\assets\n"
    }
   ],
   "source": [
    "# Save model.\n",
    "model_1.save(\"NN_1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(4813, 14) (4813,)\n"
    }
   ],
   "source": [
    "print(features.shape, label_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])"
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.engine.sequential.Sequential at 0x1f4663a5788>"
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "source": [
    "nn_model = tf.keras.models.load_model('NN_1.model/')\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('float64')"
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "testing = np.array(testing)\n",
    "testing.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "min testing:  [ 8.18680069e-14  1.07721062e-15  1.35874940e-11  4.27676526e-08\n  1.38626234e-11  6.32003060e-08  7.47888383e-12  3.24457787e-08\n  5.31321232e-08  1.00000000e+00 -2.32469180e-16 -4.49220193e-16\n -1.20301183e-15 -1.88455344e-15] max testing:  [ 8.18680069e-14  1.07721062e-15  1.35874940e-11  4.27676526e-08\n  1.38626234e-11  6.32003060e-08  7.47888383e-12  3.24457787e-08\n  5.31321232e-08  1.00000000e+00 -2.32469180e-16 -4.49220193e-16\n -1.20301183e-15 -1.88455344e-15]\n"
    }
   ],
   "source": [
    "print(\"min testing: \", min(testing), \"max testing: \", max(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.09430914, 0.19484664, 0.03007795, 0.03726863, 0.10778197,\n       0.09311236, 0.12559493, 0.10531376, 0.21169463], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "predictions = nn_model.predict([testing_reshape])[0]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda91809b139dd24b97ab06595f752137a3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}